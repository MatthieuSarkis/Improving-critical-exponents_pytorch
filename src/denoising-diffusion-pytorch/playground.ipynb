{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a50337fd96c42fa94431bb6ad82e287",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4, 64, 64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from denoising_diffusion_pytorch import Unet, GaussianDiffusion\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "trained_model_path = 'src/denoising-diffusion-pytorch/ckpt/model-3.pt'\n",
    "generated_images_path = 'src/denoising-diffusion-pytorch/generated_images'\n",
    "os.makedirs(generated_images_path, exist_ok=True)\n",
    "\n",
    "DATASET_SIZE = 100\n",
    "IMAGE_SIZE = 64\n",
    "BATCH_SIZE = 16\n",
    "PERCOLATION_PARAMETER = 0.5928\n",
    "\n",
    "model = Unet(\n",
    "    dim = 64,\n",
    "    dim_mults = (1, 2, 4, 8),\n",
    "    channels = 3\n",
    ")\n",
    "\n",
    "diffusion = GaussianDiffusion(\n",
    "    model,\n",
    "    image_size = IMAGE_SIZE,\n",
    "    #timesteps = 1000,           # number of steps\n",
    "    timesteps = 1,           # number of steps\n",
    "    #sampling_timesteps = 250,   # number of sampling timesteps (using ddim for faster inference [see citation for ddim paper])\n",
    "    sampling_timesteps = 1,   # number of sampling timesteps (using ddim for faster inference [see citation for ddim paper])\n",
    "    loss_type = 'l1'            # L1 or L2\n",
    ")\n",
    "\n",
    "sampled_images = diffusion.sample(batch_size = 4).type(torch.int8).numpy()[:,0,:,:]\n",
    "sampled_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(file=os.path.join(generated_images_path, 'test'), arr=sampled_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.load('src/denoising-diffusion-pytorch/logs/2023.03.06.15.06.34/generated_images/L=32_p=0.5928.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00041796875"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 1, ..., 0, 1, 0],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 0, 0, 1],\n",
       "       [0, 1, 1, ..., 1, 0, 0],\n",
       "       [1, 1, 0, ..., 1, 1, 0]], dtype=int8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "db83b173432a03da4f0c4835ccb6a68bd4760b75965e2dad19ac873e39f9ccbd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
